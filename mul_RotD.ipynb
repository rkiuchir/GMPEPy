{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RotD50 RotD100 for <font color='red'>multiple loop</font> \n",
    "\n",
    "### - The details are in the Boore's paper (2010BSSA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Import the modules used in this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from obspy.core import read\n",
    "from obspy.core.trace import Trace\n",
    "from obspy.signal.rotate import rotate_ne_rt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Define the cut time window function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def cut_window(array, dt, beg, end):\n",
    "        temp = Trace(data=array)\n",
    "        temp.stats.delta = dt\n",
    "        t0 = temp.stats.starttime\n",
    "        temp.trim(t0 + beg, t0 + end)\n",
    "        out = temp.data\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <font color='red'>- Calculate RotD50 and RotD100 for each station</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RotD_cal(file_accEW, file_accNS, file_velEW, file_velNS):\n",
    "    \n",
    "    '''\n",
    "    Input:\n",
    "        file_accEW: EW-comp acceleration sac file\n",
    "        file_accNS: NS-comp acceleration sac file\n",
    "        file_velEW: EW-comp velocity sac file\n",
    "        file_velNS: NS-comp velocity sac file\n",
    "        \n",
    "    Output:\n",
    "        RotD50_PGA\n",
    "        RotD100_PGA\n",
    "        RotD50_PGV\n",
    "        RotD100_PGV\n",
    "    '''\n",
    "\n",
    "    data_accEW = read(file_accEW)\n",
    "    data_accNS = read(file_accNS)\n",
    "    data_velEW = read(file_velEW)\n",
    "    data_velNS = read(file_velNS)\n",
    "\n",
    "    # Create time window\n",
    "    dt = data_accEW[0].stats.sac.delta\n",
    "    Num = data_accEW[0].stats.npts\n",
    "    x = np.linspace(0,Num*dt,Num)\n",
    "\n",
    "    # Retrieve start and end time\n",
    "    beg = data_accEW[0].stats.sac.a\n",
    "    end = data_accEW[0].stats.sac.f\n",
    "    b = data_accEW[0].stats.sac.b\n",
    "    beg = beg - b\n",
    "    end = end - b\n",
    "    \n",
    "    # Cut time window\n",
    "    t = cut_window(x, dt, beg, end)\n",
    "    accEW = cut_window(data_accEW[0].data, dt, beg, end)\n",
    "    accNS = cut_window(data_accNS[0].data, dt, beg, end)\n",
    "    velEW = cut_window(data_velEW[0].data, dt, beg, end)\n",
    "    velNS = cut_window(data_velNS[0].data, dt, beg, end)\n",
    "\n",
    "    \n",
    "    # Rotate for each 1-deg increment\n",
    "    # Rotation-angle periodicity of 180 deg\n",
    "    \n",
    "    #---Notice!!---#\n",
    "    # Basically it's good to use numpy module, if you calculate with array.\n",
    "    # But you have to prepare the empty array, when you use it.\n",
    "\n",
    "    #Prepare the empty array\n",
    "    max_acc = np.array([0.0]*180)\n",
    "    max_vel = np.array([0.0]*180)\n",
    "    \n",
    "    # Calculate Peak Amplitude over the whole rotation angles\n",
    "    # For PGA\n",
    "    for i in range(0, 180):\n",
    "        (rad, trans) = rotate_ne_rt(accNS, accEW, i)\n",
    "        ab_rad = abs(rad) \n",
    "        max_acc[i] = np.max(ab_rad)\n",
    "    \n",
    "    # For PGV\n",
    "    for i in range(0, 180):\n",
    "        (rad, trans) = rotate_ne_rt(velNS, velEW, i)\n",
    "        ab_rad = abs(rad) \n",
    "        max_vel[i] = np.max(ab_rad)\n",
    "    \n",
    "    ang = np.linspace(1,180,180)\n",
    "\n",
    "    # Pick up the maximum (RotD100) and median (RotD50) values\n",
    "    # Multiply 100 from m/sec^2 to gal for PGA and m/sec to cm/sec\n",
    "    RotD50_PGA = np.median(max_acc) * 100.0\n",
    "    RotD100_PGA = np.max(max_acc) * 100.0\n",
    "    RotD50_PGV = np.median(max_vel) * 100.0\n",
    "    RotD100_PGV = np.max(max_vel) * 100.0\n",
    "\n",
    "    return RotD50_PGA, RotD100_PGA, RotD50_PGV, RotD100_PGV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#### Read the files from \"list.txt\"\n",
    "#### For each station:\n",
    "#### accEW, accNS, velEW, velNS in each column\n",
    "infile = input()\n",
    "\n",
    "# How many stations do you have in this event?\n",
    "num_st = sum(1 for line in open(infile))\n",
    "\n",
    "# Create the empty array\n",
    "Station = np.array([\"Station\"]*num_st)\n",
    "Dist = np.array([0.0]*num_st)\n",
    "HypoDist = np.array([0.0]*num_st)\n",
    "Az = np.array([0.0]*num_st)\n",
    "RotD50_PGA = np.array([0.0]*num_st)\n",
    "RotD100_PGA = np.array([0.0]*num_st)\n",
    "RotD50_PGV = np.array([0.0]*num_st)\n",
    "RotD100_PGV = np.array([0.0]*num_st)\n",
    "Stla = np.array([0.0]*num_st)\n",
    "Stlo = np.array([0.0]*num_st)\n",
    "\n",
    "\n",
    "# Read the event header from SAC data\n",
    "f = open(infile)\n",
    "# Read for 1st column\n",
    "f1 = f.readline()\n",
    "f11, f12, f13, f14 = f1.split()\n",
    "sac = read(f11)\n",
    "\n",
    "hdr_event = str(sac[0].stats.starttime)\n",
    "hdr_event = hdr_event[0:19]\n",
    "hdr_mag = sac[0].stats.sac.mag\n",
    "hdr_depth = sac[0].stats.sac.evdp\n",
    "hdr_evla = sac[0].stats.sac.evla\n",
    "hdr_evlo = sac[0].stats.sac.evlo\n",
    "\n",
    "EventID = np.array([hdr_event]*num_st)\n",
    "Mag = np.array([hdr_mag]*num_st)\n",
    "Depth = np.array([hdr_depth]*num_st)\n",
    "Evla = np.array([hdr_evla]*num_st)\n",
    "Evlo = np.array([hdr_evlo]*num_st)\n",
    "\n",
    "\n",
    "# Main loop\n",
    "import fileinput\n",
    "i = -1\n",
    "for line in fileinput.input(infile):\n",
    "    file_accEW, file_accNS, file_velEW, file_velNS = line.split()\n",
    "    print (file_accEW, file_accNS, file_velEW, file_velNS)\n",
    "\n",
    "    # Read SAC Data\n",
    "    sac = read(file_accEW)\n",
    "    # Check the begin and end time\n",
    "    # If SAC file doesn't include these header vaules, skip this station\n",
    "    try:\n",
    "           beg = sac[0].stats.sac.a\n",
    "    except:\n",
    "           continue\n",
    "    try:\n",
    "           end = sac[0].stats.sac.f\n",
    "    except:\n",
    "           continue\n",
    "\n",
    "    # Count the station\n",
    "    i = i + 1\n",
    "    \n",
    "    # Get the station header information\n",
    "    Station[i] = sac[0].stats.station\n",
    "    Dist[i] = sac[0].stats.sac.dist\n",
    "    Az[i] = sac[0].stats.sac.az\n",
    "    Stla[i] = sac[0].stats.sac.stla\n",
    "    Stlo[i] = sac[0].stats.sac.stlo\n",
    "\n",
    "    \n",
    "    # Calculate the hypocentral distance\n",
    "    dep = sac[0].stats.sac.evdp\n",
    "    HypoDist[i] = math.sqrt(dep**2 + Dist[i]**2)\n",
    "    \n",
    "    \n",
    "    # Get the PGA PGV data \n",
    "    RotD50_PGA[i], RotD100_PGA[i], RotD50_PGV[i], RotD100_PGV[i] = RotD_cal(file_accEW, file_accNS, file_velEW, file_velNS)\n",
    "\n",
    "    \n",
    "# Create data_array for output  \n",
    "array_Name = np.c_[Station, EventID]\n",
    "array_GM = np.c_[RotD50_PGA, RotD100_PGA, RotD50_PGV, RotD100_PGV]\n",
    "array_Info = np.c_[Dist, HypoDist, Az, Mag, Depth, Stla, Stlo, Evla, Evlo]\n",
    "\n",
    "# Shrink the array size due to the skip of some stations\n",
    "array_Name = array_Name[:i+1,:]\n",
    "array_GM = array_GM[:i+1,:]\n",
    "array_Info = array_Info[:i+1,:]\n",
    "\n",
    "print(array_Name)\n",
    "\n",
    "# Convert to pandas data frame\n",
    "import pandas as pd\n",
    "Table_Name = pd.DataFrame(array_Name)\n",
    "Table_Name.columns = [\"Station\", \"EventID\"]\n",
    "print(Table_Name)\n",
    "Table_GM = pd.DataFrame(array_GM)\n",
    "Table_GM.columns = [\"RotD50_PGA\", \"RotD100_PGA\", \"RotD50_PGV\", \"RotD100_PGV\"]\n",
    "Table_Info = pd.DataFrame(array_Info)\n",
    "Table_Info.columns = [\"Dist\", \"HypoDist\", \"Az\", \"Mag\", \"Depth\", \"Stla\", \"Stlo\", \"Evla\", \"Evlo\"]\n",
    "# Change the significant figures\n",
    "Table_Info = Table_Info.round(3)\n",
    "\n",
    "# Combine Tables\n",
    "Table = pd.concat([Table_Name, Table_GM, Table_Info], axis=1)\n",
    "\n",
    "# Output for csv file\n",
    "EV = EventID[0]\n",
    "YYYYMMDD = EV[0:9]\n",
    "HH = EV[11:12]\n",
    "MM = EV[14:15]\n",
    "SS = EV[17:18]\n",
    "#Name_Table = \"\".join([\"PGA_PGV_\",EventID[0],\".csv\"])\n",
    "Name_Table = \"\".join([\"PGA_PGV_\",YYYY-MM-DD,\"_\",HH,\"-\",MM,\"-\",SS,\".csv\"])\n",
    "Table.to_csv(Name_Table)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
